import boto3
from datetime import datetime

s3_client = boto3.client('s3')
dynamodb = boto3.resource('dynamodb', region_name='us-east-1')

bucket_name = 'bellachenassignment3'
table_name = 'S3_object_size_history'

def fetch_bucket_size():
    response = s3_client.list_objects_v2(Bucket=bucket_name)
    total_size = 0
    object_count = 0
    
    if 'Contents' in response:
        for item in response['Contents']:
            total_size += item['Size']
            object_count += 1
    
    return total_size, object_count

def store_size_in_dynamodb(total_size, object_count):
    table = dynamodb.Table(table_name)
    current_timestamp = int(datetime.utcnow().timestamp())
    formatted_timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')

    table.put_item(
        Item={
            'BucketName': bucket_name,
            'Timestamp': current_timestamp,
            'TimestampStr': formatted_timestamp,
            'TotalSize': total_size,
            'ObjectCount': object_count
        }
    )

def lambda_handler(event, context):
    total_size, object_count = fetch_bucket_size()
    store_size_in_dynamodb(total_size, object_count)

    return {
        'statusCode': 200,
        'body': 'Lambda function executed and size information stored successfully.'
    }
